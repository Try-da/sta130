{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e8c0d246",
   "metadata": {},
   "source": [
    "1. The key factor is whether the idea can be quantified or measured using data. Ideas that can be expressed in numerical terms or through observable outcomes can be examined statistically, while others cannot be tested statistically.\n",
    "A good null hypothesis is clear, specific, reflects no effect or difference, is simple, and can be proven false with evidence.\n",
    "The null hypothesis states there is no effect or difference, while the alternative hypothesis suggests there is an effect or difference. It test to see if evidence rejects H₀ in favor of H₁.\n",
    "\n",
    "https://chatgpt.com/share/670f249b-a194-800f-ba95-b27bb2f70649"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ea88c48",
   "metadata": {},
   "source": [
    "2. Population is the whole group we are interested in. Sample is the smaller group we actually collected data from. Sample mean is the average value from that small group. Population mean is the true average value for the whole group, which we don’t know exactly. So we should use the sample mean to predict.\n",
    "\n",
    "https://chatgpt.com/share/670f249b-9ef0-800f-86e8-4aca7ceb93d8"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ba2cf2f",
   "metadata": {},
   "source": [
    "3. When calculating a p-value, we assume the null hypothesis is true because it sets a starting point for comparison. It’s like imagining a world where nothing unusual is happening (no effect or difference). Then, we ask: How likely is it to see data like ours, or even more extreme, in this “normal” world? If our data is very unlikely under the null hypothesis, it suggests that maybe the null isn’t true, and we might need to reconsider it. This process helps us judge if the data provides enough evidence to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d8408c",
   "metadata": {},
   "source": [
    "4. The null hypothesis is the assumption that there is no effect or difference in whatever we’re testing. The p-value tells us the probability of seeing data as extreme as ours (or more extreme) under the assumption that the null hypothesis is correct.\n",
    "So, when the p-value is small, it means our data is really surprising under the “nothing is happening” scenario. This makes us question the null hypothesis and think it might not be true, because such surprising data wouldn’t normally happen if the null hypothesis were correct."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccfdd850",
   "metadata": {},
   "source": [
    "5. By simulating 10,000 coin-flipping experiments, we obtained a p-value of 0.0004. This means that, under the assumption of the null hypothesis being true, the probability of observing 64.5% of couples tilting their heads to the right is very low—just 0.04%. According to the provided table:\n",
    "0.001 is equal or lesser than p indicates very strong evidence against the null hypothesis.\n",
    "Therefore, the results suggest that we have very strong evidence to reject the null hypothesis, implying that there might be a real tendency for couples to tilt their heads to the right when kissing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef724edb",
   "metadata": {},
   "source": [
    "6. A smaller p-value gives strong evidence against the null hypothesis but cannot prove it false. We cannot definitively prove innocence or guilt using a p-value alone. No p-value, no matter how low or high, can offer absolute proof one way or the other."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c779c816",
   "metadata": {},
   "source": [
    "7. I'm confused about what I should do in this question since Demo II of the Week 5 TUT don't have any code I think."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdfd3712",
   "metadata": {},
   "source": [
    "8.1. While the mechanics of both experiments are similar, there are key differences: The original experiment was more personalized (focused on one person’s taste sensitivity), whereas our experiment measures a broader group’s ability, potentially reflecting less specific expertise. Our sample size (80 students) is much larger than the 8 cups used in the original test.\n",
    "Null Hypothesis: The students are simply guessing, meaning there is no real ability to distinguish the order of pouring. If students are guessing, the probability of correctly identifying the order of pouring is 50%.\n",
    "Formal statement: H₀: p = 0.5, where p is the proportion of students who correctly identify the order by chance.\n",
    "Informal statement: There is no real difference in the students’ ability to identify which was poured first; they are just guessing, with a 50/50 chance of being correct.\n",
    "Alternative Hypothesis: The students have some ability to correctly identify the order of pouring, and thus the proportion of correct identifications is greater than 50%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e6d7368",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0294"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "\n",
    "# Given data\n",
    "n_students = 80  # Total number of students\n",
    "correct_identifications = 49  # Number of students who guessed correctly\n",
    "\n",
    "# Null hypothesis: 50% chance of guessing correctly (p = 0.5)\n",
    "p_null = 0.5\n",
    "\n",
    "# Simulation parameters\n",
    "n_simulations = 10000\n",
    "\n",
    "# Simulate under the null hypothesis: students randomly guessing (50% probability)\n",
    "simulated_results = np.random.binomial(n_students, p_null, n_simulations)\n",
    "\n",
    "# Calculate p-value: proportion of simulations where correct guesses >= 49\n",
    "p_value = np.mean(simulated_results >= correct_identifications)\n",
    "\n",
    "# Output p-value\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b088d176",
   "metadata": {},
   "source": [
    "8.2. we can use a binomial distribution to simulate the number of correct identifications under the null hypothesis, where each student has a 50% chance of guessing correctly. We’ll run 10,000 simulations for robustness. Then, calculate the proportion of simulations where the number of correct identifications is 49 or more, which gives us the p-value. Based on the p-value, we will assess whether we have enough evidence to reject the null hypothesis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6b7f96b",
   "metadata": {},
   "source": [
    "8.3 Since the p-value is relatively small (0.0294), it suggests that the observed result is unlikely to occur by chance if the students were merely guessing. Generally, a p-value less than 0.05 is considered statistically significant. In this case, the result provides moderate evidence against the null hypothesis, suggesting that students might have some ability to distinguish whether the tea or milk was poured first."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b3a731d",
   "metadata": {},
   "source": [
    "9. yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd44ec18",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
